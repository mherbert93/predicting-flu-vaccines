{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((26707, 38), (26708, 36))"
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train = pd.merge(pd.read_csv('training_set_features.csv'),\n",
    "                 pd.read_csv('training_set_labels.csv'))\n",
    "test = pd.read_csv('test_set_features.csv')\n",
    "sample_submission = pd.read_csv('submission_format.csv')\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "outputs": [
    {
     "data": {
      "text/plain": "   respondent_id  h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n0              0           1.0             0.0                        0.0   \n1              1           3.0             2.0                        0.0   \n2              2           1.0             1.0                        0.0   \n3              3           1.0             1.0                        0.0   \n4              4           2.0             1.0                        0.0   \n\n   behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n0                   0.0                   0.0                    0.0   \n1                   1.0                   0.0                    1.0   \n2                   1.0                   0.0                    0.0   \n3                   1.0                   0.0                    1.0   \n4                   1.0                   0.0                    1.0   \n\n   behavioral_large_gatherings  behavioral_outside_home  \\\n0                          0.0                      1.0   \n1                          0.0                      1.0   \n2                          0.0                      0.0   \n3                          1.0                      0.0   \n4                          1.0                      0.0   \n\n   behavioral_touch_face  ...  rent_or_own   employment_status  \\\n0                    1.0  ...          Own  Not in Labor Force   \n1                    1.0  ...         Rent            Employed   \n2                    0.0  ...          Own            Employed   \n3                    0.0  ...         Rent  Not in Labor Force   \n4                    1.0  ...          Own            Employed   \n\n   hhs_geo_region                census_msa  household_adults  \\\n0        oxchjgsf                   Non-MSA               0.0   \n1        bhuqouqj  MSA, Not Principle  City               0.0   \n2        qufhixun  MSA, Not Principle  City               2.0   \n3        lrircsnp       MSA, Principle City               0.0   \n4        qufhixun  MSA, Not Principle  City               1.0   \n\n   household_children  employment_industry  employment_occupation  \\\n0                 0.0                  NaN                    NaN   \n1                 0.0             pxcmvdjn               xgwztkwe   \n2                 0.0             rucpziij               xtkaffoo   \n3                 0.0                  NaN                    NaN   \n4                 0.0             wxleyezf               emcorrxb   \n\n   h1n1_vaccine  seasonal_vaccine  \n0             0                 0  \n1             0                 1  \n2             0                 0  \n3             0                 1  \n4             0                 0  \n\n[5 rows x 38 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>respondent_id</th>\n      <th>h1n1_concern</th>\n      <th>h1n1_knowledge</th>\n      <th>behavioral_antiviral_meds</th>\n      <th>behavioral_avoidance</th>\n      <th>behavioral_face_mask</th>\n      <th>behavioral_wash_hands</th>\n      <th>behavioral_large_gatherings</th>\n      <th>behavioral_outside_home</th>\n      <th>behavioral_touch_face</th>\n      <th>...</th>\n      <th>rent_or_own</th>\n      <th>employment_status</th>\n      <th>hhs_geo_region</th>\n      <th>census_msa</th>\n      <th>household_adults</th>\n      <th>household_children</th>\n      <th>employment_industry</th>\n      <th>employment_occupation</th>\n      <th>h1n1_vaccine</th>\n      <th>seasonal_vaccine</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>Own</td>\n      <td>Not in Labor Force</td>\n      <td>oxchjgsf</td>\n      <td>Non-MSA</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>Rent</td>\n      <td>Employed</td>\n      <td>bhuqouqj</td>\n      <td>MSA, Not Principle  City</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>pxcmvdjn</td>\n      <td>xgwztkwe</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>Own</td>\n      <td>Employed</td>\n      <td>qufhixun</td>\n      <td>MSA, Not Principle  City</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>rucpziij</td>\n      <td>xtkaffoo</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>Rent</td>\n      <td>Not in Labor Force</td>\n      <td>lrircsnp</td>\n      <td>MSA, Principle City</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>Own</td>\n      <td>Employed</td>\n      <td>qufhixun</td>\n      <td>MSA, Not Principle  City</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>wxleyezf</td>\n      <td>emcorrxb</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 38 columns</p>\n</div>"
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "outputs": [],
   "source": [
    "# from pandas_profiling import ProfileReport\n",
    "# profile = ProfileReport(train, minimal=True).to_notebook_iframe()\n",
    "#\n",
    "# profile"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "outputs": [],
   "source": [
    "def wrangle(X):\n",
    "    X = X.copy()\n",
    "\n",
    "    X = X.drop(['respondent_id'], axis=1)\n",
    "\n",
    "    return X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "outputs": [],
   "source": [
    "train = wrangle(train)\n",
    "test = wrangle(test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "outputs": [],
   "source": [
    "target = ['h1n1_vaccine', 'seasonal_vaccine']\n",
    "\n",
    "train_features = train.drop(target, axis=1)\n",
    "\n",
    "features = train_features.nunique().index.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "outputs": [],
   "source": [
    "y_train = train[target]\n",
    "X_train = train[features]\n",
    "\n",
    "X_test = test[features]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest best score: 0.8560847983771906\n",
      "Random Forest best score: 0.8580955373682522\n",
      "Random Forest best score: 0.8580955373682522\n",
      "Random Forest best score: 0.8580955373682522\n",
      "Random Forest best score: 0.8580955373682522\n",
      "Random Forest best score: 0.8580955373682522\n",
      "Random Forest best score: 0.8583970553639922\n",
      "Random Forest best score: 0.8583970553639922\n",
      "Random Forest best score: 0.8583970553639922\n",
      "Random Forest best score: 0.8589689514934646\n",
      "Random Forest best score: 0.8589689514934646\n",
      "Random Forest best score: 0.8589689514934646\n",
      "Random Forest best score: 0.8589689514934646\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.8590210034413924\n",
      "Random Forest best score: 0.859039615733202\n",
      "Random Forest best score: 0.859039615733202\n",
      "XGboost best score: 0.8563859127697088\n",
      "XGboost best score: 0.8563859127697088\n",
      "XGboost best score: 0.863664173649026\n",
      "XGboost best score: 0.863664173649026\n",
      "XGboost best score: 0.863664173649026\n",
      "XGboost best score: 0.863664173649026\n",
      "XGboost best score: 0.8646834552968151\n",
      "XGboost best score: 0.8646834552968151\n",
      "XGboost best score: 0.8646834552968151\n",
      "XGboost best score: 0.8646834552968151\n",
      "XGboost best score: 0.8646834552968151\n",
      "XGboost best score: 0.8646834552968151\n",
      "XGboost best score: 0.8648753823129134\n",
      "XGboost best score: 0.8648753823129134\n",
      "XGboost best score: 0.8648753823129134\n",
      "XGboost best score: 0.8648753823129134\n",
      "XGboost best score: 0.8648753823129134\n",
      "XGboost best score: 0.8648753823129134\n",
      "XGboost best score: 0.8648753823129134\n",
      "XGboost best score: 0.8648753823129134\n",
      "XGboost best score: 0.8648753823129134\n",
      "XGboost best score: 0.8652698314059938\n",
      "XGboost best score: 0.8652698314059938\n",
      "XGboost best score: 0.8652698314059938\n",
      "XGboost best score: 0.8652698314059938\n",
      "XGboost best score: 0.8652698314059938\n",
      "XGboost best score: 0.8652698314059938\n",
      "XGboost best score: 0.8652698314059938\n",
      "XGboost best score: 0.8652698314059938\n",
      "XGboost best score: 0.865290664052286\n",
      "XGboost best score: 0.865290664052286\n",
      "XGboost best score: 0.865659594959731\n",
      "XGboost best score: 0.865659594959731\n",
      "XGboost best score: 0.865659594959731\n",
      "XGboost best score: 0.865659594959731\n",
      "XGboost best score: 0.865659594959731\n",
      "XGboost best score: 0.865659594959731\n",
      "XGboost best score: 0.865659594959731\n",
      "XGboost best score: 0.865659594959731\n",
      "XGboost best score: 0.865659594959731\n",
      "XGboost best score: 0.865659594959731\n",
      "XGboost best score: 0.865659594959731\n",
      "XGboost best score: 0.865659594959731\n",
      "XGboost best score: 0.865659594959731\n",
      "XGboost best score: 0.865659594959731\n",
      "XGboost best score: 0.865659594959731\n",
      "XGboost best score: 0.865659594959731\n",
      "XGboost best score: 0.865659594959731\n",
      "XGboost best score: 0.865659594959731\n",
      "XGboost best score: 0.865659594959731\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as ce\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "#When hyperparamater tuning, set tune to \"True\", and mark each model that we want to tune to \"True\".\n",
    "tune = True\n",
    "forest = True\n",
    "xgboost = True\n",
    "\n",
    "forest_distributions = {\n",
    "    'model__n_estimators': [50, 100, 150, 200, 250, 300, 325, 350],\n",
    "    'model__max_depth': [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30],\n",
    "    'model__max_features': [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
    "                            31, 32, 33, 34, 35],\n",
    "    'model__min_samples_leaf': [2, 3, 4, 5, 6, 7, 8]\n",
    "}\n",
    "\n",
    "xgboost_distributions = {\n",
    "    'model__estimator__n_estimators': [125, 150, 175, 200, 225, 250, 260, 275, 300, 325, 350, 375, 400, 425, 450, 475, 500],\n",
    "    'model__estimator__max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30],\n",
    "    'model__estimator__learning_rate': [0.01, 0.03, 0.05, 0.07, 0.09, 0.10, 0.12, 0.14, 0.16, 0.18, 0.20, 0.22, 0.24, 0.26, 0.28, 0.30],\n",
    "    'model__estimator__min_child_leaf':[1, 2, 3, 4, 5, 6],\n",
    "    'model__estimator__min_child_weight': [1, 2, 3, 4, 5, 6],\n",
    "    'model__estimator__colsample_bytree':[0.1, 0.15, 0.2, 0.3, 0.4, 0.50],\n",
    "    'model__estimator__subsample':[0.6, 0.7, 0.8, 0.9, 1],\n",
    "    'model__estimator__gamma':[0, 1, 2, 3, 4, 5],\n",
    "    'model__estimator__scale_pos_weight': [20, 25, 30, 35, 40, 45, 50, 60]\n",
    " }\n",
    "\n",
    "# forest_distributions = {\n",
    "#     'model__n_estimators': [350, 375, 400, 425],\n",
    "#     'model__max_depth': [29, 30, 31, 32, 33],\n",
    "#     'model__max_features': [24, 25, 26, 27],\n",
    "#     'model__min_samples_leaf': [4]\n",
    "# }\n",
    "\n",
    "# xgboost_distributions = {\n",
    "#     'model__n_estimators': [260, 265, 270],\n",
    "#     'model__max_depth': [26, 27],\n",
    "#     'model__learning_rate': [0.08, 0.09],\n",
    "#     'model__min_child_leaf':[3],\n",
    "#     'model__min_child_weight': [4],\n",
    "#     'model__colsample_bytree':[0.2],\n",
    "#     'model__subsample':[0.9, 1],\n",
    "#     'model__gamma':[0],\n",
    "#     'model__scale_pos_weight': [25]\n",
    "#   }\n",
    "\n",
    "if tune: #If we are hyperparamater tuning, pass no parameters into estimators and find paramaters via GridSearchCV / RandomizedSearchCV\n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore') #ignore warnings generated by bayes search\n",
    "\n",
    "    forest_pipeline = Pipeline([('encoder', ce.OrdinalEncoder()),\n",
    "                                ('imputer', SimpleImputer(strategy='mean')),\n",
    "                           ('model', RandomForestClassifier(random_state=1337))])\n",
    "\n",
    "    xgboost_pipeline = Pipeline([('encoder', ce.OrdinalEncoder()),\n",
    "                                 ('imputer', SimpleImputer(strategy='mean')),\n",
    "                           ('model', MultiOutputClassifier(XGBClassifier(seed=1337)))])\n",
    "\n",
    "    forest_search = BayesSearchCV(\n",
    "        forest_pipeline,\n",
    "        search_spaces=forest_distributions,\n",
    "        n_iter=250,\n",
    "        cv=5,\n",
    "        scoring='roc_auc',\n",
    "        random_state=1337,\n",
    "        n_points=5,\n",
    "        n_jobs=15\n",
    "    )\n",
    "    xgboost_search = BayesSearchCV(\n",
    "        estimator=xgboost_pipeline,\n",
    "        search_spaces=xgboost_distributions,\n",
    "        n_iter=250,\n",
    "        cv=5,\n",
    "        scoring='roc_auc',\n",
    "        random_state=1337,\n",
    "        n_points=5,\n",
    "        n_jobs=15\n",
    "    )\n",
    "\n",
    "    # forest_search = GridSearchCV(\n",
    "    #     estimator=forest_pipeline,\n",
    "    #     param_grid=forest_distributions,\n",
    "    #     cv=3,\n",
    "    #     verbose=3,\n",
    "    #     scoring='f1_micro',\n",
    "    #     n_jobs=15\n",
    "    # )\n",
    "    # xgboost_search = GridSearchCV(\n",
    "    #     estimator=xgboost_pipeline,\n",
    "    #     param_grid=xgboost_distributions,\n",
    "    #     cv=3,\n",
    "    #     verbose=3,\n",
    "    #     scoring='f1_micro',\n",
    "    #     n_jobs=15\n",
    "    # )\n",
    "\n",
    "    def report_step_forest(optim_result):\n",
    "        score = forest_search.best_score_\n",
    "        print(\"Random Forest best score: %s\" % score)\n",
    "\n",
    "    def report_step_xgboost(optim_result):\n",
    "        score = xgboost_search.best_score_\n",
    "        print(\"XGboost best score: %s\" % score)\n",
    "\n",
    "    #X_train, y_train = RandomOverSampler(sampling_strategy='not majority').fit_resample(X_train, y_train)\n",
    "\n",
    "    if forest:\n",
    "        forest_search.fit(X_train, y_train, callback=report_step_forest)\n",
    "        forest_train_pred_proba = forest_search.predict_proba(X_train)\n",
    "        forest_test_pred_proba = forest_search.predict_proba(X_test)\n",
    "\n",
    "    if xgboost:\n",
    "        xgboost_search.fit(X_train, y_train, callback=report_step_xgboost)\n",
    "        xgboost_train_pred_proba = xgboost_search.predict_proba(X_train)\n",
    "        xgboost_test_pred_proba = xgboost_search.predict_proba(X_test)\n",
    "\n",
    "    #When hyperparameter tuning, pass our best estimators into votingclassifier. Only run when all 3 models are being tuned.\n",
    "    # if forest and xgboost:\n",
    "    #     voting_model = VotingClassifier(estimators=[('forest', forest_search.best_estimator_), #VotingClassifier is Soft Voting/Majority Rule classifier for unfitted estimators\n",
    "    #                                                 ('xgboost', xgboost_search.best_estimator_),],\n",
    "    #                                     voting='soft') #soft voting per recommendation from sklearn documentation, when used on tuned classifiers.\n",
    "    #     voting_model_cv = voting_model\n",
    "    #     voting_model.fit(X_train, y_train)\n",
    "    #     combined_model_test_pred = voting_model.predict(X_test)\n",
    "\n",
    "else: #If we are not hyperparameter tuning, pass in our best params(from previous tuning runs).\n",
    "    forest_pipeline = Pipeline([('encoder', ce.OrdinalEncoder()),\n",
    "                                ('imputer', SimpleImputer(strategy='mean')),\n",
    "                            ('model', RandomForestClassifier(random_state=1337, n_jobs=14, max_depth=22,\n",
    "                                                             min_samples_leaf=6, max_features=6, n_estimators=350))])\n",
    "\n",
    "    xgboost_pipeline = Pipeline([('encoder', ce.OrdinalEncoder()),\n",
    "                                ('model', XGBClassifier(seed=1337, n_jobs=15, colsample_bytree=0.3, gamma=3,\n",
    "                                                        learning_rate=0.1, max_depth=3, min_child_leaf=1, min_child_weight=5,\n",
    "                                                        n_estimators=375, scale_pos_weight=20, subsample=0.9))])\n",
    "\n",
    "\n",
    "    #X_train, y_train = RandomOverSampler(sampling_strategy='minority').fit_resample(X_train, y_train) #over sample all but the majority class\n",
    "\n",
    "    forest_pipeline_cv = forest_pipeline\n",
    "    forest_pipeline.fit(X_train, y_train)\n",
    "    forest_train_pred_proba = forest_pipeline.predict_proba(X_train)\n",
    "    forest_test_pred_proba = forest_pipeline.predict_proba(X_test)\n",
    "\n",
    "    # xgboost_pipeline_cv = xgboost_pipeline\n",
    "    # xgboost_pipeline.fit(X_train, y_train)\n",
    "    # xgboost_train_pred = xgboost_pipeline.predict(X_train)\n",
    "    # xgboost_test_pred = xgboost_pipeline.predict(X_test)\n",
    "\n",
    "    # voting_model = VotingClassifier(estimators=[('forest', forest_pipeline), #VotingClassifier is Soft Voting/Majority Rule classifier for unfitted estimators\n",
    "    #                                             ('xgboost', xgboost_pipeline),],\n",
    "    #                                 voting='soft') #soft voting per recommendation from sklearn documentation, when used on tuned classifiers.\n",
    "    # voting_model_cv = voting_model\n",
    "    # voting_model.fit(X_train, y_train)\n",
    "    # combined_model_test_pred = voting_model.predict(X_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('model__max_depth', 22), ('model__max_features', 6), ('model__min_samples_leaf', 6), ('model__n_estimators', 350)]) \n",
      "\n",
      "Best Random Forest CV score:  0.859039615733202 \n",
      "\n",
      "\n",
      "\n",
      "OrderedDict([('model__estimator__colsample_bytree', 0.3), ('model__estimator__gamma', 3), ('model__estimator__learning_rate', 0.1), ('model__estimator__max_depth', 3), ('model__estimator__min_child_leaf', 1), ('model__estimator__min_child_weight', 5), ('model__estimator__n_estimators', 375), ('model__estimator__scale_pos_weight', 20), ('model__estimator__subsample', 0.9)]) \n",
      "\n",
      "Best xgboost CV score:  0.865659594959731 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "if tune:\n",
    "    if forest:\n",
    "        print(forest_search.best_params_, '\\n')\n",
    "        print(\"Best Random Forest CV score: \", forest_search.best_score_, '\\n')\n",
    "        print('\\n')\n",
    "\n",
    "    if xgboost:\n",
    "        print(xgboost_search.best_params_, '\\n')\n",
    "        print(\"Best xgboost CV score: \", xgboost_search.best_score_, '\\n')\n",
    "        print('\\n')\n",
    "\n",
    "    # if forest and xgboost:\n",
    "    #     #print(\"Voting classifier, final F1-Micro score on validation set: \", f1_score(y_validation, combined_model_pred, average='micro'))\n",
    "    #     print(\"Voting classifier, final F1-Micro cross-validation score: \", np.mean(cross_val_score(voting_model_cv, X_train,\n",
    "    #                                                                                         y_train, scoring='f1_micro',\n",
    "    #                                                                                         cv=3, n_jobs=15)))\n",
    "else:\n",
    "    # print(\"Random forest F1-Micro cross-validation score: \", np.mean(cross_val_score(forest_pipeline_cv, X_train,\n",
    "    #                                                                          y_train, scoring='f1_micro', cv=3,\n",
    "    #                                                                          n_jobs=15)), '\\n')\n",
    "    # print('\\n')\n",
    "\n",
    "    print(\"Random forest ROC AUC cross validation score: \", np.mean(cross_val_score(forest_pipeline_cv, X_train, y_train, scoring='roc_auc', cv=5,\n",
    "                                                n_jobs=14)), '\\n')\n",
    "\n",
    "\n",
    "    #print('\\n')\n",
    "\n",
    "    #print(\"Random forest ROC AUC training score: \", roc_auc_score(y_train, forest_train_pred_proba))\n",
    "    #\n",
    "    # print(\"Voting classifier, final F1-Micro cross-validation score: \", np.mean(cross_val_score(voting_model_cv, X_train,\n",
    "    #                                                                                         y_train, scoring='f1_micro',\n",
    "    #                                                                                         cv=3, n_jobs=15)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [],
   "source": [
    "\n",
    "# Make sure we have the rows in the same order\n",
    "submission = sample_submission.copy()\n",
    "np.testing.assert_array_equal(X_test.index.values,\n",
    "                              submission.index.values)\n",
    "\n",
    "# Save predictions to submission data frame\n",
    "submission[\"h1n1_vaccine\"] = forest_test_pred_proba[0][:, 1]\n",
    "submission[\"seasonal_vaccine\"] = forest_test_pred_proba[1][:, 1]\n",
    "submission.to_csv('random_forest.csv', index=False)\n",
    "\n",
    "submission = sample_submission.copy()\n",
    "np.testing.assert_array_equal(X_test.index.values,\n",
    "                              submission.index.values)\n",
    "\n",
    "submission[\"h1n1_vaccine\"] = xgboost_test_pred_proba[0][:, 1]\n",
    "submission[\"seasonal_vaccine\"] = xgboost_test_pred_proba[1][:, 1]\n",
    "submission.to_csv('xgboost.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "outputs": [
    {
     "data": {
      "text/plain": "   respondent_id  h1n1_vaccine  seasonal_vaccine\n0          26707      0.748527          0.876982\n1          26708      0.344693          0.294949\n2          26709      0.802015          0.979315\n3          26710      0.967905          0.992940\n4          26711      0.929897          0.952205",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>respondent_id</th>\n      <th>h1n1_vaccine</th>\n      <th>seasonal_vaccine</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>26707</td>\n      <td>0.748527</td>\n      <td>0.876982</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26708</td>\n      <td>0.344693</td>\n      <td>0.294949</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26709</td>\n      <td>0.802015</td>\n      <td>0.979315</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>26710</td>\n      <td>0.967905</td>\n      <td>0.992940</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>26711</td>\n      <td>0.929897</td>\n      <td>0.952205</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}